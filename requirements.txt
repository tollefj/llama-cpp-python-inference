torch
python-dotenv
jsonlines
transformers
# llama-cpp-python[server]